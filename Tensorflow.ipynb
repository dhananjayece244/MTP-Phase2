{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DTW calculation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob \n",
    "import pickle\n",
    "from math import *\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.fftpack import fft\n",
    "from dtw import dtw\n",
    "from numpy import array, zeros, argmin, inf, ndim\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "from sklearn import svm\n",
    "import tensorflow as tf\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "# from quatrotate import qv_mult # this routine implements rotation via quaternion multiplication\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_contiguous_colors(colors):\n",
    "    # finds the continuous segments of colors and returns those segments\n",
    "    segs = []\n",
    "    curr_seg = []\n",
    "    prev_color = ''\n",
    "    for c in colors:\n",
    "        if c == prev_color or prev_color == '':\n",
    "            curr_seg.append(c)\n",
    "        else:\n",
    "            segs.append(curr_seg)\n",
    "            curr_seg = []\n",
    "            curr_seg.append(c)\n",
    "        prev_color = c\n",
    "    segs.append(curr_seg) # the final one\n",
    "    return segs\n",
    " \n",
    "def plot_multicolored_lines(x,y,colors):\n",
    "    segments = find_contiguous_colors(colors)\n",
    "    plt.figure(figsize=(20,4))\n",
    "    start= 0\n",
    "    for seg in segments:\n",
    "        end = start + len(seg)\n",
    "        l, = plt.gca().plot(x[start-1:end+1],y[start-1:end+1],lw=2,c=seg[0]) \n",
    "        start = end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to map the colors as a list from the input list of x variables\n",
    "def color_mapping(lst):\n",
    "    cols=[]\n",
    "    colors = {'ST':'blue', 'LT':'red','RT':'green'}\n",
    "    for l in lst:\n",
    "        cols.append(colors[l])      \n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GaussianFilter(df, window_length):\n",
    "    df1 = df\n",
    "    \n",
    "    df1['AX'] = gaussian_filter(df['AX'], window_length)\n",
    "    df1['AY'] = gaussian_filter(df['AY'], window_length)\n",
    "    df1['AZ'] = gaussian_filter(df['AZ'], window_length)\n",
    "\n",
    "    df1['GX'] = gaussian_filter(df['GX'], window_length)\n",
    "    df1['GY'] = gaussian_filter(df['GY'], window_length)\n",
    "    df1['GZ'] = gaussian_filter(df['GZ'], window_length)\n",
    "    \n",
    "    df1['AX1'] = gaussian_filter(df['AX1'], window_length)\n",
    "    df1['AY1'] = gaussian_filter(df['AY1'], window_length)\n",
    "    df1['AZ1'] = gaussian_filter(df['AZ1'], window_length)\n",
    "\n",
    "    df1['GX1'] = gaussian_filter(df['GX1'], window_length)\n",
    "    df1['GY1'] = gaussian_filter(df['GY1'], window_length)\n",
    "    df1['GZ1'] = gaussian_filter(df['GZ1'], window_length)\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Amplitude(df, input_features, out_feature):\n",
    "    df[out_feature] = (df[input_features[0]]**2 + df[input_features[1]]**2  + df[input_features[2]]**2)**(1/2)\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Yaw_Roll_Pitch(df):\n",
    "    roll  = []\n",
    "    pitch = []\n",
    "    yaw   = []\n",
    "    for i in range(len(df)):\n",
    "        x = df['AX'][i]\n",
    "        y = df['AY'][i]\n",
    "        z = df['AZ'][i]\n",
    "        roll1 = atan(y/z)*57.3\n",
    "        pitch1= atan((-x/(y*y + z*z)**(1/2)))*57.3\n",
    "        yaw1  = atan((z/((x*x + z*z)**(1/2))))*57.3\n",
    "        \n",
    "        roll.append(roll1)\n",
    "        pitch.append(pitch1)\n",
    "        yaw.append(yaw1)\n",
    "    \n",
    "    df['orientX'] = pitch\n",
    "    df['orientY'] = roll\n",
    "    df['orientZ'] = yaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getQuat(df):\n",
    "\n",
    "        \"\"\" Given 3 orientation angles, compute the quaternion. \"\"\"\n",
    "\n",
    "        yaw   = df['orientZ'] / 2. * np.pi / 180\n",
    "        roll  = df['orientX'] / 2. * np.pi / 180\n",
    "        pitch = df['orientY'] / 2. * np.pi / 180\n",
    "\n",
    "        w =  np.cos(roll) * np.cos(pitch) * np.cos(yaw) + \\\n",
    "                np.sin(roll) * np.sin(pitch) * np.sin(yaw)\n",
    "\n",
    "        x =  np.sin(roll) * np.cos(pitch) * np.cos(yaw) - \\\n",
    "                np.cos(roll) * np.sin(pitch) * np.sin(yaw)\n",
    "\n",
    "        y =  np.cos(roll) * np.sin(pitch) * np.cos(yaw) + \\\n",
    "                np.sin(roll) * np.cos(pitch) * np.sin(yaw)\n",
    "\n",
    "        z =  np.cos(roll) * np.cos(pitch) * np.sin(yaw) - \\\n",
    "                np.sin(roll) * np.sin(pitch) * np.cos(yaw)\n",
    "\n",
    "        return w, x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Rotate a 3D vector using the axis-angle method (quaternions).\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def normalize(v, tolerance=0.00001):\n",
    "    mag2 = sum(n * n for n in v)\n",
    "    if abs(mag2 - 1.0) > tolerance:\n",
    "        mag = np.sqrt(mag2)\n",
    "        v = tuple(n / mag for n in v)\n",
    "    return v\n",
    "\n",
    "def q_mult(q1, q2):\n",
    "    w1, x1, y1, z1 = q1\n",
    "    w2, x2, y2, z2 = q2\n",
    "    w = w1 * w2 - x1 * x2 - y1 * y2 - z1 * z2\n",
    "    x = w1 * x2 + x1 * w2 + y1 * z2 - z1 * y2\n",
    "    y = w1 * y2 + y1 * w2 + z1 * x2 - x1 * z2\n",
    "    z = w1 * z2 + z1 * w2 + x1 * y2 - y1 * x2\n",
    "    return w, x, y, z\n",
    "\n",
    "def q_conjugate(q):\n",
    "    w, x, y, z = q\n",
    "    return (w, -x, -y, -z)\n",
    "\n",
    "def qv_mult(q1, v1):\n",
    "    q2 = (0.0,) + v1\n",
    "    return q_mult(q_mult(q1, q2), q_conjugate(q1))[1:]\n",
    "\n",
    "def axisangle_to_q(v, theta):\n",
    "    v = normalize(v)\n",
    "    x, y, z = v\n",
    "    theta /= 2\n",
    "    w = np.cos(theta)\n",
    "    x = x * np.sin(theta)\n",
    "    y = y * np.sin(theta)\n",
    "    z = z * np.sin(theta)\n",
    "    return w, x, y, z\n",
    "\n",
    "def q_to_axisangle(q):\n",
    "    w, v = q[0], q[1:]\n",
    "    theta = np.acos(w) * 2.0\n",
    "    return normalize(v), theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_rotation(quatern, vector):\n",
    "    rotaedvector = []\n",
    "    for i in range(vector.shape[0]):\n",
    "        rotaedvector.append(qv_mult(tuple(quatern[i,:]), tuple(vector[i,:])))\n",
    "    return np.array(rotaedvector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rotate(df):\n",
    "    features = ['A', 'G']\n",
    "    quaternion = df[['quaternionW', 'quaternionX',\n",
    "                     'quaternionY','quaternionZ']].values\n",
    "    \n",
    "    for f in features:\n",
    "        xyzlist = [f + 'X', f + 'Y', f + 'Z']\n",
    "        xyz = df[xyzlist].values\n",
    "        xyz_rotated = get_rotation(quaternion, xyz)\n",
    "        df[f + 'X1'] = xyz_rotated[:,0]\n",
    "        df[f + 'Y1'] = xyz_rotated[:,1]\n",
    "        df[f + 'Z1'] = xyz_rotated[:,2]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate frequency domain data from time domain data usinf Fast Fourier transformation\n",
    "\n",
    "def FFT(df, input_features, output_features):\n",
    "    \n",
    "    for i in range(len(input_features)):\n",
    "        reals = np.real(np.fft.rfft(df[input_features[i]]))\n",
    "        imagn = np.imag(np.fft.rfft(df[input_features[i]]))\n",
    "\n",
    "        complexs = [reals[0]]\n",
    "        n = len(reals)\n",
    "        if(n%2 == 0):\n",
    "            complexs.append(imagn[0])\n",
    "        for j in range(1, n-1):\n",
    "            complexs.append(reals[j])\n",
    "            complexs.append(imagn[j])\n",
    "        if( len(df) > len(complexs)):\n",
    "            complexs.append(reals[j])\n",
    "        if( len(df) > len(complexs)):\n",
    "            complexs.append(imagn[j])\n",
    "            \n",
    "        df[output_features[i]] = complexs\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def segmentation(df, N_TIME_STEPS):\n",
    "    \n",
    "    N_FEATURES = 1\n",
    "    step = 50\n",
    "    segments = []\n",
    "    labels = []\n",
    "    for i in range(0, len(df) - N_TIME_STEPS, step):\n",
    "        gx = df['GX1'].values[i: i + N_TIME_STEPS]\n",
    "        gy = df['GY1'].values[i: i + N_TIME_STEPS]\n",
    "        gz = df['GZ1'].values[i: i + N_TIME_STEPS]\n",
    "        \n",
    "        ax = df['AX1'].values[i: i + N_TIME_STEPS]\n",
    "        ay = df['AY1'].values[i: i + N_TIME_STEPS]\n",
    "        az = df['AZ1'].values[i: i + N_TIME_STEPS]\n",
    "        \n",
    "        fax = df['fAX'].values[i: i + N_TIME_STEPS]\n",
    "        fay = df['fAY'].values[i: i + N_TIME_STEPS]\n",
    "        faz = df['fAZ'].values[i: i + N_TIME_STEPS]\n",
    "        \n",
    "        ma = df['mAcc'].values[i: i + N_TIME_STEPS]\n",
    "        mz = df['mGyro'].values[i: i + N_TIME_STEPS]\n",
    "        label = \"ST\"\n",
    "        segments.append([gx, gy, gz, ax, ay, az, ma, mz, fax, fay, faz])\n",
    "#         labels = stats.mode(df['activity'][i: i + N_TIME_STEPS])[0][0]\n",
    "        labels.append(label)\n",
    "    return segments, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DTWDistance(s1, s2, w):\n",
    "    DTW={}\n",
    "\n",
    "    w = max(w, abs(len(s1)-len(s2)))\n",
    "\n",
    "    for i in range(-1,len(s1)):\n",
    "        for j in range(-1,len(s2)):\n",
    "            DTW[(i, j)] = float('inf')\n",
    "    DTW[(-1, -1)] = 0\n",
    "\n",
    "    for i in range(len(s1)):\n",
    "        for j in range(max(0, i-w), min(len(s2), i+w)):\n",
    "            dist= (s1[i]-s2[j])**2\n",
    "            DTW[(i, j)] = dist + min(DTW[(i-1, j)],DTW[(i, j-1)], DTW[(i-1, j-1)])\n",
    "\n",
    "    return (DTW[len(s1)-1, len(s2)-1])**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_for_segments(segments, comp, feature):\n",
    "    loss =[]\n",
    "    labels=[]\n",
    "    length = len(segments)\n",
    "    for i in range(length):\n",
    "        x = segments[i][feature]        \n",
    "        dist = DTWDistance(x, comp, 50)\n",
    "#         print(i , '=>', dist)\n",
    "        loss.append(dist)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_preprocessing(df):\n",
    "    \n",
    "    #mean feature of 3-axis accelerometer data\n",
    "    input_features = ['AX', 'AY', 'AZ']\n",
    "    output_feature = 'mAcc'\n",
    "    Amplitude(df, input_features, output_feature)\n",
    "    \n",
    "    #mean feature of 3-axis gyroscope data\n",
    "    input_features = ['GX', 'GY', 'GZ']\n",
    "    output_feature = 'mGyro'\n",
    "    Amplitude(df, input_features, output_feature)\n",
    "    \n",
    "    #Re-Orientation of 3-axis acc. and gyro sensor data\n",
    "    Yaw_Roll_Pitch(df)\n",
    "    qw, qx, qy, qz = getQuat(df)\n",
    "    df['quaternionW'] = qw\n",
    "    df['quaternionX'] = qx\n",
    "    df['quaternionY'] = qy\n",
    "    df['quaternionZ'] = qz\n",
    "    rotate(df)\n",
    "    #apply gaussian filter with window size 10\n",
    "    df = GaussianFilter(df, 10)\n",
    "\n",
    "    #Frequency domain feature generation from time series accelerometer data\n",
    "    input_features = ['AX1', 'AY1', 'AZ1']\n",
    "    output_feature = ['fAX', 'fAY', 'fAZ']\n",
    "    df = FFT(df, input_features, output_feature)\n",
    "    \n",
    "    #Frequency domain feature generation from time series gyroscope data\n",
    "    input_features = ['AX1', 'AY1', 'AZ1']\n",
    "    output_feature = ['fGX', 'fGY', 'fGZ']\n",
    "    df = FFT(df, input_features, output_feature)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read csv file and return its data-frame\n",
    "def read_csv_file(acc, gyro, mode):\n",
    "    df_gyro = pd.read_csv(gyro, index_col=False)\n",
    "    df      = pd.read_csv(acc,  index_col=False)\n",
    "    df.rename(columns = {'X': 'AX', 'Y':'AY', 'Z':'AZ'}, inplace = True)\n",
    "    df['GX'] = df_gyro['X']\n",
    "    df['GY'] = df_gyro['Y']\n",
    "    df['GZ'] = df_gyro['Z']\n",
    "    \n",
    "    df['activity'] = mode\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_files(acc_file, gyro_file, activity):\n",
    "    df = read_csv_file(acc_file, gyro_file, activity)\n",
    "    df.reset_index(drop = True , inplace = True)\n",
    "    if('Milliseconds' in df.columns):\n",
    "        df = df.drop('Milliseconds', axis=1)\n",
    "    if('Timestamp' in df.columns):\n",
    "        df = df.drop('Timestamp', axis=1)\n",
    "\n",
    "    df = data_preprocessing(df)\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vicky/Desktop/Dhananjay/human-activity/data/bike/Bike0903/2018-09-03_16-06-48/AccelerometerLinear.csv\n",
      "/home/vicky/Desktop/Dhananjay/human-activity/data/bike/Bike0903/2018-09-03_16-06-48/Gyroscope.csv\n",
      "len of this file  (302, 28)\n",
      "len of this file  (0, 28)\n",
      "(0, 28)\n",
      "/home/vicky/Desktop/Dhananjay/human-activity/data/bike/Bike0903/2018-09-03_15-58-17/AccelerometerLinear.csv\n",
      "/home/vicky/Desktop/Dhananjay/human-activity/data/bike/Bike0903/2018-09-03_15-58-17/Gyroscope.csv\n",
      "len of this file  (11674, 28)\n",
      "len of this file  (10824, 28)\n",
      "(10824, 28)\n",
      "/home/vicky/Desktop/Dhananjay/human-activity/data/bike/Bike0903/2018-09-03_16-12-17/AccelerometerLinear.csv\n",
      "/home/vicky/Desktop/Dhananjay/human-activity/data/bike/Bike0903/2018-09-03_16-12-17/Gyroscope.csv\n",
      "len of this file  (10141, 28)\n",
      "len of this file  (9291, 28)\n",
      "(20115, 28)\n",
      "/home/vicky/Desktop/Dhananjay/human-activity/data/bike/Bike0903/2018-09-03_15-53-27/AccelerometerLinear.csv\n",
      "/home/vicky/Desktop/Dhananjay/human-activity/data/bike/Bike0903/2018-09-03_15-53-27/Gyroscope.csv\n",
      "len of this file  (10831, 28)\n",
      "len of this file  (9981, 28)\n",
      "(30096, 28)\n",
      "/home/vicky/Desktop/Dhananjay/human-activity/data/bike/Bike0903/2018-09-03_16-03-12/AccelerometerLinear.csv\n",
      "/home/vicky/Desktop/Dhananjay/human-activity/data/bike/Bike0903/2018-09-03_16-03-12/Gyroscope.csv\n",
      "len of this file  (10432, 28)\n",
      "len of this file  (9582, 28)\n",
      "(39678, 28)\n",
      "/home/vicky/Desktop/Dhananjay/human-activity/data/bike/Bike0903/2018-09-03_16-16-05/AccelerometerLinear.csv\n",
      "/home/vicky/Desktop/Dhananjay/human-activity/data/bike/Bike0903/2018-09-03_16-16-05/Gyroscope.csv\n",
      "len of this file  (10889, 28)\n",
      "len of this file  (10039, 28)\n",
      "(49717, 28)\n",
      "/home/vicky/Desktop/Dhananjay/human-activity/data/bike/bike50/2018-08-08_15-08-54/AccelerometerLinear.csv\n",
      "/home/vicky/Desktop/Dhananjay/human-activity/data/bike/bike50/2018-08-08_15-08-54/Gyroscope.csv\n",
      "len of this file  (4709, 28)\n",
      "len of this file  (3859, 28)\n",
      "(53576, 28)\n",
      "/home/vicky/Desktop/Dhananjay/human-activity/data/bike/bike50/2018-08-08_15-12-47/AccelerometerLinear.csv\n",
      "/home/vicky/Desktop/Dhananjay/human-activity/data/bike/bike50/2018-08-08_15-12-47/Gyroscope.csv\n",
      "len of this file  (2849, 28)\n",
      "len of this file  (1999, 28)\n",
      "(55575, 28)\n",
      "/home/vicky/Desktop/Dhananjay/human-activity/data/bike/bike50/2018-08-08_15-15-20/AccelerometerLinear.csv\n",
      "/home/vicky/Desktop/Dhananjay/human-activity/data/bike/bike50/2018-08-08_15-15-20/Gyroscope.csv\n",
      "len of this file  (369, 28)\n",
      "len of this file  (0, 28)\n",
      "(55575, 28)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AX</th>\n",
       "      <th>AY</th>\n",
       "      <th>AZ</th>\n",
       "      <th>GX</th>\n",
       "      <th>GY</th>\n",
       "      <th>GZ</th>\n",
       "      <th>activity</th>\n",
       "      <th>mAcc</th>\n",
       "      <th>mGyro</th>\n",
       "      <th>orientX</th>\n",
       "      <th>...</th>\n",
       "      <th>AZ1</th>\n",
       "      <th>GX1</th>\n",
       "      <th>GY1</th>\n",
       "      <th>GZ1</th>\n",
       "      <th>fAX</th>\n",
       "      <th>fAY</th>\n",
       "      <th>fAZ</th>\n",
       "      <th>fGX</th>\n",
       "      <th>fGY</th>\n",
       "      <th>fGZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.007023</td>\n",
       "      <td>0.112130</td>\n",
       "      <td>-0.430526</td>\n",
       "      <td>-0.133173</td>\n",
       "      <td>-0.076351</td>\n",
       "      <td>0.104627</td>\n",
       "      <td>bike</td>\n",
       "      <td>1.033584</td>\n",
       "      <td>0.355847</td>\n",
       "      <td>-19.020191</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.339794</td>\n",
       "      <td>-0.109928</td>\n",
       "      <td>-0.013069</td>\n",
       "      <td>0.113804</td>\n",
       "      <td>25.880820</td>\n",
       "      <td>146.803098</td>\n",
       "      <td>-86.776934</td>\n",
       "      <td>25.880820</td>\n",
       "      <td>146.803098</td>\n",
       "      <td>-86.776934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.003683</td>\n",
       "      <td>0.139261</td>\n",
       "      <td>-0.417439</td>\n",
       "      <td>-0.141457</td>\n",
       "      <td>-0.077701</td>\n",
       "      <td>0.103369</td>\n",
       "      <td>bike</td>\n",
       "      <td>1.199937</td>\n",
       "      <td>0.379878</td>\n",
       "      <td>-17.621220</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.319991</td>\n",
       "      <td>-0.114300</td>\n",
       "      <td>-0.011571</td>\n",
       "      <td>0.113162</td>\n",
       "      <td>32.421071</td>\n",
       "      <td>52.301557</td>\n",
       "      <td>-21.304957</td>\n",
       "      <td>32.421071</td>\n",
       "      <td>52.301557</td>\n",
       "      <td>-21.304957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000853</td>\n",
       "      <td>0.167799</td>\n",
       "      <td>-0.401824</td>\n",
       "      <td>-0.148915</td>\n",
       "      <td>-0.078951</td>\n",
       "      <td>0.101645</td>\n",
       "      <td>bike</td>\n",
       "      <td>1.686179</td>\n",
       "      <td>0.369426</td>\n",
       "      <td>2.516505</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.297427</td>\n",
       "      <td>-0.118204</td>\n",
       "      <td>-0.010350</td>\n",
       "      <td>0.112090</td>\n",
       "      <td>73.125050</td>\n",
       "      <td>-23.648178</td>\n",
       "      <td>47.068088</td>\n",
       "      <td>73.125050</td>\n",
       "      <td>-23.648178</td>\n",
       "      <td>47.068088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006639</td>\n",
       "      <td>0.197498</td>\n",
       "      <td>-0.383849</td>\n",
       "      <td>-0.155505</td>\n",
       "      <td>-0.080184</td>\n",
       "      <td>0.099483</td>\n",
       "      <td>bike</td>\n",
       "      <td>0.843485</td>\n",
       "      <td>0.343799</td>\n",
       "      <td>-2.775456</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.272269</td>\n",
       "      <td>-0.121649</td>\n",
       "      <td>-0.009453</td>\n",
       "      <td>0.110630</td>\n",
       "      <td>-36.111748</td>\n",
       "      <td>93.802537</td>\n",
       "      <td>-5.337681</td>\n",
       "      <td>-36.111748</td>\n",
       "      <td>93.802537</td>\n",
       "      <td>-5.337681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.013667</td>\n",
       "      <td>0.228047</td>\n",
       "      <td>-0.363736</td>\n",
       "      <td>-0.161207</td>\n",
       "      <td>-0.081489</td>\n",
       "      <td>0.096916</td>\n",
       "      <td>bike</td>\n",
       "      <td>2.172636</td>\n",
       "      <td>0.342391</td>\n",
       "      <td>82.421936</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.244741</td>\n",
       "      <td>-0.124649</td>\n",
       "      <td>-0.008932</td>\n",
       "      <td>0.108831</td>\n",
       "      <td>2.880542</td>\n",
       "      <td>97.677857</td>\n",
       "      <td>42.925926</td>\n",
       "      <td>2.880542</td>\n",
       "      <td>97.677857</td>\n",
       "      <td>42.925926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         AX        AY        AZ        GX        GY        GZ activity  \\\n",
       "0 -0.007023  0.112130 -0.430526 -0.133173 -0.076351  0.104627     bike   \n",
       "1 -0.003683  0.139261 -0.417439 -0.141457 -0.077701  0.103369     bike   \n",
       "2  0.000853  0.167799 -0.401824 -0.148915 -0.078951  0.101645     bike   \n",
       "3  0.006639  0.197498 -0.383849 -0.155505 -0.080184  0.099483     bike   \n",
       "4  0.013667  0.228047 -0.363736 -0.161207 -0.081489  0.096916     bike   \n",
       "\n",
       "       mAcc     mGyro    orientX    ...           AZ1       GX1       GY1  \\\n",
       "0  1.033584  0.355847 -19.020191    ...     -0.339794 -0.109928 -0.013069   \n",
       "1  1.199937  0.379878 -17.621220    ...     -0.319991 -0.114300 -0.011571   \n",
       "2  1.686179  0.369426   2.516505    ...     -0.297427 -0.118204 -0.010350   \n",
       "3  0.843485  0.343799  -2.775456    ...     -0.272269 -0.121649 -0.009453   \n",
       "4  2.172636  0.342391  82.421936    ...     -0.244741 -0.124649 -0.008932   \n",
       "\n",
       "        GZ1        fAX         fAY        fAZ        fGX         fGY  \\\n",
       "0  0.113804  25.880820  146.803098 -86.776934  25.880820  146.803098   \n",
       "1  0.113162  32.421071   52.301557 -21.304957  32.421071   52.301557   \n",
       "2  0.112090  73.125050  -23.648178  47.068088  73.125050  -23.648178   \n",
       "3  0.110630 -36.111748   93.802537  -5.337681 -36.111748   93.802537   \n",
       "4  0.108831   2.880542   97.677857  42.925926   2.880542   97.677857   \n",
       "\n",
       "         fGZ  \n",
       "0 -86.776934  \n",
       "1 -21.304957  \n",
       "2  47.068088  \n",
       "3  -5.337681  \n",
       "4  42.925926  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  \n",
    "path_acc = os.getcwd() + '/data/bike/*/*/*AccelerometerLinear.csv'  \n",
    "path_gyro= os.getcwd() + '/data/bike/*/*/*Gyroscope.csv'  \n",
    "acc_files = glob.glob(path_acc)\n",
    "gyro_files= glob.glob(path_gyro)\n",
    "bike_df= read_files(acc_files[0], gyro_files[0], 'bike')\n",
    "n = len(bike_df)\n",
    "bike_df = bike_df[500:n-500]\n",
    "for acc_file, gyro_file in zip(acc_files, gyro_files) :\n",
    "    print(acc_file)\n",
    "    print(gyro_file)\n",
    "    df_this = read_files(acc_file, gyro_file, 'bike')\n",
    "    n = len(df_this)\n",
    "    print(\"len of this file \",df_this.shape)\n",
    "    df_this = df_this[350 : n-500]\n",
    "    print(\"len of this file \",df_this.shape)\n",
    "    bike_df = pd.concat([bike_df, df_this])\n",
    "    print(bike_df.shape)\n",
    "bike_df.reset_index(drop = True, inplace = True)\n",
    "bike_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55575, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['AX', 'AY', 'AZ', 'GX', 'GY', 'GZ', 'activity', 'mAcc', 'mGyro',\n",
       "       'orientX', 'orientY', 'orientZ', 'quaternionW', 'quaternionX',\n",
       "       'quaternionY', 'quaternionZ', 'AX1', 'AY1', 'AZ1', 'GX1', 'GY1', 'GZ1',\n",
       "       'fAX', 'fAY', 'fAZ', 'fGX', 'fGY', 'fGZ'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(bike_df.shape)\n",
    "bike_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1104, 11, 400)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_segments, bike_labels = segmentation(bike_df, 400)\n",
    "np.array(bike_segments).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vicky/Desktop/Dhananjay/human-activity/data/car1/car/2018-08-17_16-43-04/AccelerometerLinear.csv\n",
      "/home/vicky/Desktop/Dhananjay/human-activity/data/car1/car/2018-08-17_16-43-04/Gyroscope.csv\n",
      "len of this file  (6646, 28)\n",
      "len of this file  (5796, 28)\n",
      "(11592, 28)\n",
      "/home/vicky/Desktop/Dhananjay/human-activity/data/car1/car/2018-08-17_16-54-34/AccelerometerLinear.csv\n",
      "/home/vicky/Desktop/Dhananjay/human-activity/data/car1/car/2018-08-17_16-54-34/Gyroscope.csv\n",
      "len of this file  (325, 28)\n",
      "len of this file  (0, 28)\n",
      "(11592, 28)\n",
      "/home/vicky/Desktop/Dhananjay/human-activity/data/car1/car/2018-08-17_16-45-30/AccelerometerLinear.csv\n",
      "/home/vicky/Desktop/Dhananjay/human-activity/data/car1/car/2018-08-17_16-45-30/Gyroscope.csv\n",
      "len of this file  (6770, 28)\n",
      "len of this file  (5920, 28)\n",
      "(17512, 28)\n",
      "/home/vicky/Desktop/Dhananjay/human-activity/data/car1/car/2018-08-17_16-54-46/AccelerometerLinear.csv\n",
      "/home/vicky/Desktop/Dhananjay/human-activity/data/car1/car/2018-08-17_16-54-46/Gyroscope.csv\n",
      "len of this file  (5293, 28)\n",
      "len of this file  (4443, 28)\n",
      "(21955, 28)\n",
      "/home/vicky/Desktop/Dhananjay/human-activity/data/car1/car/2018-08-17_16-50-00/AccelerometerLinear.csv\n",
      "/home/vicky/Desktop/Dhananjay/human-activity/data/car1/car/2018-08-17_16-50-00/Gyroscope.csv\n",
      "len of this file  (13444, 28)\n",
      "len of this file  (12594, 28)\n",
      "(34549, 28)\n",
      "/home/vicky/Desktop/Dhananjay/human-activity/data/car1/car/2018-08-17_13-52-47/AccelerometerLinear.csv\n",
      "/home/vicky/Desktop/Dhananjay/human-activity/data/car1/car/2018-08-17_13-52-47/Gyroscope.csv\n",
      "len of this file  (15570, 28)\n",
      "len of this file  (14720, 28)\n",
      "(49269, 28)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AX</th>\n",
       "      <th>AY</th>\n",
       "      <th>AZ</th>\n",
       "      <th>GX</th>\n",
       "      <th>GY</th>\n",
       "      <th>GZ</th>\n",
       "      <th>activity</th>\n",
       "      <th>mAcc</th>\n",
       "      <th>mGyro</th>\n",
       "      <th>orientX</th>\n",
       "      <th>...</th>\n",
       "      <th>AZ1</th>\n",
       "      <th>GX1</th>\n",
       "      <th>GY1</th>\n",
       "      <th>GZ1</th>\n",
       "      <th>fAX</th>\n",
       "      <th>fAY</th>\n",
       "      <th>fAZ</th>\n",
       "      <th>fGX</th>\n",
       "      <th>fGY</th>\n",
       "      <th>fGZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.274150</td>\n",
       "      <td>0.386046</td>\n",
       "      <td>-0.116917</td>\n",
       "      <td>0.034840</td>\n",
       "      <td>0.137716</td>\n",
       "      <td>0.332758</td>\n",
       "      <td>car</td>\n",
       "      <td>0.882817</td>\n",
       "      <td>0.233839</td>\n",
       "      <td>-63.984609</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181182</td>\n",
       "      <td>0.091135</td>\n",
       "      <td>0.031582</td>\n",
       "      <td>0.245277</td>\n",
       "      <td>22.431667</td>\n",
       "      <td>-34.025393</td>\n",
       "      <td>8.622702</td>\n",
       "      <td>22.431667</td>\n",
       "      <td>-34.025393</td>\n",
       "      <td>8.622702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.250386</td>\n",
       "      <td>0.374052</td>\n",
       "      <td>-0.113326</td>\n",
       "      <td>0.035408</td>\n",
       "      <td>0.116555</td>\n",
       "      <td>0.339397</td>\n",
       "      <td>car</td>\n",
       "      <td>1.370899</td>\n",
       "      <td>0.218887</td>\n",
       "      <td>23.101936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174576</td>\n",
       "      <td>0.086128</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>0.244226</td>\n",
       "      <td>-0.893364</td>\n",
       "      <td>12.487488</td>\n",
       "      <td>-4.808171</td>\n",
       "      <td>-0.893364</td>\n",
       "      <td>12.487488</td>\n",
       "      <td>-4.808171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.226391</td>\n",
       "      <td>0.362938</td>\n",
       "      <td>-0.109220</td>\n",
       "      <td>0.035289</td>\n",
       "      <td>0.096402</td>\n",
       "      <td>0.342103</td>\n",
       "      <td>car</td>\n",
       "      <td>1.577567</td>\n",
       "      <td>0.223861</td>\n",
       "      <td>51.300015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165708</td>\n",
       "      <td>0.080448</td>\n",
       "      <td>0.019058</td>\n",
       "      <td>0.241016</td>\n",
       "      <td>4.278284</td>\n",
       "      <td>-14.240124</td>\n",
       "      <td>-1.744896</td>\n",
       "      <td>4.278284</td>\n",
       "      <td>-14.240124</td>\n",
       "      <td>-1.744896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.202447</td>\n",
       "      <td>0.352584</td>\n",
       "      <td>-0.104442</td>\n",
       "      <td>0.034548</td>\n",
       "      <td>0.077432</td>\n",
       "      <td>0.341075</td>\n",
       "      <td>car</td>\n",
       "      <td>2.392651</td>\n",
       "      <td>0.637923</td>\n",
       "      <td>58.367552</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154992</td>\n",
       "      <td>0.074300</td>\n",
       "      <td>0.013742</td>\n",
       "      <td>0.235883</td>\n",
       "      <td>0.723327</td>\n",
       "      <td>-32.780075</td>\n",
       "      <td>-41.302828</td>\n",
       "      <td>0.723327</td>\n",
       "      <td>-32.780075</td>\n",
       "      <td>-41.302828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.178788</td>\n",
       "      <td>0.342868</td>\n",
       "      <td>-0.098848</td>\n",
       "      <td>0.033261</td>\n",
       "      <td>0.059779</td>\n",
       "      <td>0.336601</td>\n",
       "      <td>car</td>\n",
       "      <td>0.679046</td>\n",
       "      <td>0.835866</td>\n",
       "      <td>-47.974722</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142876</td>\n",
       "      <td>0.067882</td>\n",
       "      <td>0.008987</td>\n",
       "      <td>0.229098</td>\n",
       "      <td>8.278835</td>\n",
       "      <td>-24.641124</td>\n",
       "      <td>19.177460</td>\n",
       "      <td>8.278835</td>\n",
       "      <td>-24.641124</td>\n",
       "      <td>19.177460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         AX        AY        AZ        GX        GY        GZ activity  \\\n",
       "0 -0.274150  0.386046 -0.116917  0.034840  0.137716  0.332758      car   \n",
       "1 -0.250386  0.374052 -0.113326  0.035408  0.116555  0.339397      car   \n",
       "2 -0.226391  0.362938 -0.109220  0.035289  0.096402  0.342103      car   \n",
       "3 -0.202447  0.352584 -0.104442  0.034548  0.077432  0.341075      car   \n",
       "4 -0.178788  0.342868 -0.098848  0.033261  0.059779  0.336601      car   \n",
       "\n",
       "       mAcc     mGyro    orientX    ...           AZ1       GX1       GY1  \\\n",
       "0  0.882817  0.233839 -63.984609    ...      0.181182  0.091135  0.031582   \n",
       "1  1.370899  0.218887  23.101936    ...      0.174576  0.086128  0.024991   \n",
       "2  1.577567  0.223861  51.300015    ...      0.165708  0.080448  0.019058   \n",
       "3  2.392651  0.637923  58.367552    ...      0.154992  0.074300  0.013742   \n",
       "4  0.679046  0.835866 -47.974722    ...      0.142876  0.067882  0.008987   \n",
       "\n",
       "        GZ1        fAX        fAY        fAZ        fGX        fGY        fGZ  \n",
       "0  0.245277  22.431667 -34.025393   8.622702  22.431667 -34.025393   8.622702  \n",
       "1  0.244226  -0.893364  12.487488  -4.808171  -0.893364  12.487488  -4.808171  \n",
       "2  0.241016   4.278284 -14.240124  -1.744896   4.278284 -14.240124  -1.744896  \n",
       "3  0.235883   0.723327 -32.780075 -41.302828   0.723327 -32.780075 -41.302828  \n",
       "4  0.229098   8.278835 -24.641124  19.177460   8.278835 -24.641124  19.177460  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_acc = os.getcwd() + '/data/car1/*/*/*AccelerometerLinear.csv'  \n",
    "path_gyro= os.getcwd() + '/data/car1/*/*/*Gyroscope.csv'\n",
    "acc_files = glob.glob(path_acc)\n",
    "gyro_files= glob.glob(path_gyro)\n",
    "car_df= read_files(acc_files[0], gyro_files[0], 'car')\n",
    "n = len(car_df)\n",
    "car_df = car_df[350:n-500]\n",
    "for acc_file, gyro_file in zip(acc_files, gyro_files) :\n",
    "    print(acc_file)\n",
    "    print(gyro_file)\n",
    "    df_this = read_files(acc_file, gyro_file, 'car')\n",
    "    n = len(df_this)\n",
    "    print(\"len of this file \",df_this.shape)\n",
    "    df_this = df_this[350 : n-500]\n",
    "    print(\"len of this file \",df_this.shape)\n",
    "    car_df = pd.concat([car_df, df_this])\n",
    "    print(car_df.shape)\n",
    "car_df.reset_index(drop = True, inplace = True)\n",
    "car_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49269, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['AX', 'AY', 'AZ', 'GX', 'GY', 'GZ', 'activity', 'mAcc', 'mGyro',\n",
       "       'orientX', 'orientY', 'orientZ', 'quaternionW', 'quaternionX',\n",
       "       'quaternionY', 'quaternionZ', 'AX1', 'AY1', 'AZ1', 'GX1', 'GY1', 'GZ1',\n",
       "       'fAX', 'fAY', 'fAZ', 'fGX', 'fGY', 'fGZ'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(car_df.shape)\n",
    "car_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(978, 11, 400)\n",
      "(1104, 11, 400)\n"
     ]
    }
   ],
   "source": [
    "car_segments, car_labels = segmentation(car_df, 400)\n",
    "print(np.array(car_segments).shape)\n",
    "print(np.array(bike_segments).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# car_seg = [*zip(*(car_segments[]))]\n",
    "car_seg = np.transpose(car_segments, axes=(0, 2, 1)).tolist()\n",
    "bike_seg = np.transpose(bike_segments, axes=(0, 2, 1)).tolist()\n",
    "# seg = [list(x) for x in zip(*car_segments)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(978, 400, 11)\n",
      "(1104, 400, 11)\n",
      "2082\n"
     ]
    }
   ],
   "source": [
    "print(np.array(car_seg).shape)\n",
    "print(np.array(bike_seg).shape)\n",
    "\n",
    "label1 = [1]*len(car_seg)     #lebel = 1 to all bike samples\n",
    "\n",
    "label2 = [0]*len(bike_seg)\n",
    "label = label1 + label2\n",
    "print(len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = car_seg + bike_seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = pd.Series(seg)\n",
    "label = pd.Series(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RANDOM_SEED = 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(seg, label, test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1665,)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input Data \n",
    "\n",
    "training_data_count = len(X_train)  # 7352 training series (with 50% overlap between each serie)\n",
    "test_data_count = len(X_test)  # 2947 testing series\n",
    "n_steps = len(X_train[0])  # 128 timesteps per series\n",
    "n_input = len(X_train[0][0])  # 9 input parameters per timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1665 417 400 11\n"
     ]
    }
   ],
   "source": [
    "print(training_data_count, test_data_count,n_steps, n_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden = 16 # Hidden layer num of features\n",
    "n_classes = 2 # Total classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some useful info to get an insight on dataset's shape and normalisation:\n",
      "(X shape, y shape, every X's mean, every X's standard deviation)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'method' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-867a2d326ea3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Some useful info to get an insight on dataset's shape and normalisation:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"(X shape, y shape, every X's mean, every X's standard deviation)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The dataset is therefore properly normalised, as expected, but not yet one-hot encoded.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   2907\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[0;32m-> 2909\u001b[0;31m                           out=out, **kwargs)\n\u001b[0m\u001b[1;32m   2910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mrcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mrcount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'method' and 'int'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training \n",
    "\n",
    "learning_rate = 0.0025\n",
    "lambda_loss_amount = 0.0015\n",
    "training_iters = training_data_count * 300  # Loop 300 times on the dataset\n",
    "batch_size = 100\n",
    "display_iter = 30  # To show test set accuracy during training\n",
    "\n",
    "\n",
    "# Some debugging info\n",
    "\n",
    "print(\"Some useful info to get an insight on dataset's shape and normalisation:\")\n",
    "print(\"(X shape, y shape, every X's mean, every X's standard deviation)\")\n",
    "print(X_test.shape, y_test.shape, np.mean(X_test.tolist), np.std(X_test.tolist))\n",
    "print(\"The dataset is therefore properly normalised, as expected, but not yet one-hot encoded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LSTM_RNN(_X, _weights, _biases):\n",
    "    # Function returns a tensorflow LSTM (RNN) artificial neural network from given parameters. \n",
    "    # Moreover, two LSTM cells are stacked which adds deepness to the neural network. \n",
    "    # Note, some code of this notebook is inspired from an slightly different \n",
    "    # RNN architecture used on another dataset, some of the credits goes to \n",
    "    # \"aymericdamien\" under the MIT license.\n",
    "\n",
    "    # (NOTE: This step could be greatly optimised by shaping the dataset once\n",
    "    # input shape: (batch_size, n_steps, n_input)\n",
    "    _X = tf.transpose(_X, [1, 0, 2])  # permute n_steps and batch_size\n",
    "    # Reshape to prepare input to hidden activation\n",
    "    _X = tf.reshape(_X, [-1, n_input]) \n",
    "    # new shape: (n_steps*batch_size, n_input)\n",
    "    \n",
    "    # ReLU activation, thanks to Yu Zhao for adding this improvement here:\n",
    "    _X = tf.nn.relu(tf.matmul(_X, _weights['hidden']) + _biases['hidden'])\n",
    "    # Split data because rnn cell needs a list of inputs for the RNN inner loop\n",
    "    _X = tf.split(_X, n_steps, 0) \n",
    "    # new shape: n_steps * (batch_size, n_hidden)\n",
    "\n",
    "    # Define two stacked LSTM cells (two recurrent layers deep) with tensorflow\n",
    "    lstm_cell_1 = tf.contrib.rnn.BasicLSTMCell(n_hidden, forget_bias=1.0, state_is_tuple=True)\n",
    "    lstm_cell_2 = tf.contrib.rnn.BasicLSTMCell(n_hidden, forget_bias=1.0, state_is_tuple=True)\n",
    "    lstm_cells = tf.contrib.rnn.MultiRNNCell([lstm_cell_1, lstm_cell_2], state_is_tuple=True)\n",
    "    # Get LSTM cell output\n",
    "    outputs, states = tf.contrib.rnn.static_rnn(lstm_cells, _X, dtype=tf.float32)\n",
    "\n",
    "    # Get last time step's output feature for a \"many-to-one\" style classifier, \n",
    "    # as in the image describing RNNs at the top of this page\n",
    "    lstm_last_output = outputs[-1]\n",
    "    \n",
    "    # Linear activation\n",
    "    return tf.matmul(lstm_last_output, _weights['out']) + _biases['out']\n",
    "\n",
    "\n",
    "def extract_batch_size(_train, step, batch_size):\n",
    "    # Function to fetch a \"batch_size\" amount of data from \"(X|y)_train\" data. \n",
    "    \n",
    "    shape = list(_train.shape)\n",
    "    shape[0] = batch_size\n",
    "    batch_s = np.empty(shape)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        # Loop index\n",
    "        index = ((step-1)*batch_size + i) % len(_train)\n",
    "        batch_s[i] = _train[index] \n",
    "\n",
    "    return batch_s\n",
    "\n",
    "\n",
    "def one_hot(y_, n_classes=n_classes):\n",
    "    # Function to encode neural one-hot output labels from number indexes \n",
    "    # e.g.: \n",
    "    # one_hot(y_=[[5], [0], [3]], n_classes=6):\n",
    "    #     return [[0, 0, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0]]\n",
    "    \n",
    "    y_ = y_.reshape(len(y_))\n",
    "    return np.eye(n_classes)[np.array(y_, dtype=np.int32)]  # Returns FLOATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-68-1d1bcade311a>:22: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
      "WARNING:tensorflow:From <ipython-input-69-40d01f8fa6ae>:21: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2320\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2321\u001b[0;31m         \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2322\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Operation 'rnn/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/concat_178' has no attr named '_XlaCompile'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[0;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m       \u001b[0mxla_compile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_XlaCompile\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m       xla_separate_compiled_gradients = op.get_attr(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2324\u001b[0m       \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2325\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2326\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Operation 'rnn/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/concat_178' has no attr named '_XlaCompile'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-40d01f8fa6ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m ) # L2 loss prevents this overkill neural network to overfit the data\n\u001b[1;32m     21\u001b[0m \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml2\u001b[0m \u001b[0;31m# Softmax loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Adam Optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mcorrect_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0maggregation_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation_method\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m         grad_loss=grad_loss)\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[0mvars_with_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36mcompute_gradients\u001b[0;34m(self, loss, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, grad_loss)\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0mgate_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgate_gradients\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGATE_OP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0maggregation_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation_method\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m         colocate_gradients_with_ops=colocate_gradients_with_ops)\n\u001b[0m\u001b[1;32m    518\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgate_gradients\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGATE_GRAPH\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m       \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontrol_flow_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients)\u001b[0m\n\u001b[1;32m    594\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     return _GradientsHelper(ys, xs, grad_ys, name, colocate_gradients_with_ops,\n\u001b[0;32m--> 596\u001b[0;31m                             gate_gradients, aggregation_method, stop_gradients)\n\u001b[0m\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, src_graph)\u001b[0m\n\u001b[1;32m    774\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 776\u001b[0;31m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    777\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[0;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[1;32m    396\u001b[0m       \u001b[0mxla_scope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_XlaScope\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Exit early\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mxla_compile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    774\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 776\u001b[0;31m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    777\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_grad.py\u001b[0m in \u001b[0;36m_ConcatGradV2\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_ConcatGradV2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m   return _ConcatGradHelper(\n\u001b[0;32m--> 222\u001b[0;31m       op, grad, start_value_index=0, end_value_index=-1, dim_index=-1)\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_grad.py\u001b[0m in \u001b[0;36m_ConcatGradHelper\u001b[0;34m(op, grad, start_value_index, end_value_index, dim_index)\u001b[0m\n\u001b[1;32m    130\u001b[0m       \u001b[0;31m# Using mod here for convenience since concat_dim is already verified\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m       \u001b[0;31m# in concat implementation to be within the allowed [-rank, rank) range.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m       \u001b[0mnon_neg_concat_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat_dim\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m       \u001b[0;31m# Get the inputs' tensor shapes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mrank\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m    366\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mend_compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m   \"\"\"\n\u001b[0;32m--> 368\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mrank_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mrank_internal\u001b[0;34m(input, name, optimize)\u001b[0m\n\u001b[1;32m    389\u001b[0m       \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0moptimize\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    203\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m   \u001b[0mtensor_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m   tensor_value.tensor.CopyFrom(\n\u001b[0m\u001b[1;32m    206\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[1;32m    207\u001b[0m           value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Graph input/output\n",
    "x = tf.placeholder(tf.float32, [None, n_steps, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "# Graph weights\n",
    "weights = {\n",
    "    'hidden': tf.Variable(tf.random_normal([n_input, n_hidden])), # Hidden layer weights\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, n_classes], mean=1.0))\n",
    "}\n",
    "biases = {\n",
    "    'hidden': tf.Variable(tf.random_normal([n_hidden])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "pred = LSTM_RNN(x, weights, biases)\n",
    "\n",
    "# Loss, optimizer and evaluation\n",
    "l2 = lambda_loss_amount * sum(\n",
    "    tf.nn.l2_loss(tf_var) for tf_var in tf.trainable_variables()\n",
    ") # L2 loss prevents this overkill neural network to overfit the data\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=pred)) + l2 # Softmax loss\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost) # Adam Optimizer\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To keep track of training's performance\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "\n",
    "# Launch the graph\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(log_device_placement=True))\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "# Perform Training steps with \"batch_size\" amount of example data at each loop\n",
    "step = 1\n",
    "while step * batch_size <= training_iters:\n",
    "    batch_xs =         extract_batch_size(X_train, step, batch_size)\n",
    "    batch_ys = one_hot(extract_batch_size(y_train, step, batch_size))\n",
    "\n",
    "    # Fit training using batch data\n",
    "    _, loss, acc = sess.run(\n",
    "        [optimizer, cost, accuracy],\n",
    "        feed_dict={\n",
    "            x: batch_xs, \n",
    "            y: batch_ys\n",
    "        }\n",
    "    )\n",
    "    train_losses.append(loss)\n",
    "    train_accuracies.append(acc)\n",
    "    \n",
    "    # Evaluate network only at some steps for faster training: \n",
    "    if (step*batch_size % display_iter == 0) or (step == 1) or (step * batch_size > training_iters):\n",
    "        \n",
    "        # To not spam console, show training accuracy/loss in this \"if\"\n",
    "        print(\"Training iter #\" + str(step*batch_size) + \\\n",
    "              \":   Batch Loss = \" + \"{:.6f}\".format(loss) + \\\n",
    "              \", Accuracy = {}\".format(acc))\n",
    "        \n",
    "        # Evaluation on the test set (no learning made here - just evaluation for diagnosis)\n",
    "        loss, acc = sess.run(\n",
    "            [cost, accuracy], \n",
    "            feed_dict={\n",
    "                x: X_test,\n",
    "                y: one_hot(y_test)\n",
    "            }\n",
    "        )\n",
    "        test_losses.append(loss)\n",
    "        test_accuracies.append(acc)\n",
    "        print(\"PERFORMANCE ON TEST SET: \" + \\\n",
    "              \"Batch Loss = {}\".format(loss) + \\\n",
    "              \", Accuracy = {}\".format(acc))\n",
    "\n",
    "    step += 1\n",
    "\n",
    "print(\"Optimization Finished!\")\n",
    "\n",
    "# Accuracy for test data\n",
    "\n",
    "one_hot_predictions, accuracy, final_loss = sess.run(\n",
    "    [pred, accuracy, cost],\n",
    "    feed_dict={\n",
    "        x: X_test,\n",
    "        y: one_hot(y_test)\n",
    "    }\n",
    ")\n",
    "\n",
    "test_losses.append(final_loss)\n",
    "test_accuracies.append(accuracy)\n",
    "\n",
    "print(\"FINAL RESULT: \" + \\\n",
    "      \"Batch Loss = {}\".format(final_loss) + \\\n",
    "      \", Accuracy = {}\".format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
